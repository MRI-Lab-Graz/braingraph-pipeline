# Quick Decision Tree: Which Scripts Am I Using?

## ğŸ¯ Choose Your Workflow

### âœ… **I want to optimize parameters (find best settings)**
```
Use: opticonn sweep
Calls: cross_validation_bootstrap_optimizer.py
  â”œâ”€â”€ sweep_utils.py (grid generation)
  â”œâ”€â”€ run_pipeline.py (per combo)
  â”‚  â”œâ”€â”€ extract_connectivity_matrices.py
  â”‚  â”œâ”€â”€ aggregate_network_measures.py
  â”‚  â””â”€â”€ qa_cross_validator.py
  â”‚      [PREVENTS: Layer 1 & 2]
  â””â”€â”€ bootstrap_qa_validator.py
      [PREVENTS: Layer 3]

Then: opticonn review
  â””â”€â”€ Auto-select best combo

Output: selected_candidate.json
```

### âœ… **I want to apply known-good parameters to my full dataset**
```
Use: opticonn apply
Calls: run_pipeline.py (full dataset)
  â”œâ”€â”€ extract_connectivity_matrices.py
  â”œâ”€â”€ aggregate_network_measures.py
  â”œâ”€â”€ qa_cross_validator.py
  â”‚  [PREVENTS: Layer 1 & 2]
  â””â”€â”€ bootstrap_qa_validator.py
      [PREVENTS: Layer 3]

Output: Analysis-ready connectivity matrices
```

### âœ… **I want to run a single connectivity extraction (manual testing)**
```
Use: opticonn pipeline --step all
Calls: run_pipeline.py
  â”œâ”€â”€ extract_connectivity_matrices.py
  â”œâ”€â”€ aggregate_network_measures.py
  â”œâ”€â”€ qa_cross_validator.py
  â”‚  [PREVENTS: Layer 1 & 2]
  â””â”€â”€ bootstrap_qa_validator.py
      [PREVENTS: Layer 3]

Output: Single connectivity matrix + metrics
```

---

## ğŸ“Š Script Dependency Tree

```
ENTRY POINTS (User runs these):
â”œâ”€â”€ opticonn_hub.py (main CLI)
â”œâ”€â”€ run_pipeline.py (single combo pipeline)
â””â”€â”€ opticonn.py (legacy entry, routes to opticonn_hub.py)

USED BY SWEEPS ONLY:
â”œâ”€â”€ cross_validation_bootstrap_optimizer.py
â”‚   â””â”€â”€ sweep_utils.py (grid building)
â”œâ”€â”€ run_parameter_sweep.py (legacy)
â””â”€â”€ pareto_view.py (post-sweep analysis)

USED BY ALL WORKFLOWS (extract & score):
â”œâ”€â”€ extract_connectivity_matrices.py
â”‚   â””â”€â”€ dsi_studio_tools/utils.py
â”œâ”€â”€ aggregate_network_measures.py
â”œâ”€â”€ qa_cross_validator.py â­ [PREVENTION: Layer 1 & 2]
â””â”€â”€ bootstrap_qa_validator.py â­ [PREVENTION: Layer 3]

VALIDATION & SETUP:
â”œâ”€â”€ validate_setup.py
â”œâ”€â”€ pre_test_validation.py
â”œâ”€â”€ scripts/test/** (unit tests)
â””â”€â”€ utils/* (utility functions)

ADVANCED ANALYSIS:
â”œâ”€â”€ sensitivity_analyzer.py (not auto-run)
â”œâ”€â”€ statistical_analysis.py (not auto-run)
â”œâ”€â”€ statistical_metric_comparator.py (not auto-run)
â””â”€â”€ metric_optimizer.py (not auto-run)
```

---

## ğŸ—‘ï¸ Safe to Remove (if not doing parameter sweeps)

| Script | Used By | Safe? |
|--------|---------|-------|
| `pareto_view.py` | Manual sweep analysis | âœ… Yes (post-processing only) |
| `sweep_utils.py` | Parameter grid generation | âœ… Yes (sweep-only utilities) |
| `run_parameter_sweep.py` | Legacy sweep runner | âœ… Yes (replaced by cross_validation_bootstrap_optimizer.py) |
| `sensitivity_analyzer.py` | Research analysis | âœ… Yes (optional analysis) |
| `statistical_analysis.py` | Research analysis | âœ… Yes (optional analysis) |
| `statistical_metric_comparator.py` | Research analysis | âœ… Yes (optional analysis) |
| `metric_optimizer.py` | Research optimization | âœ… Yes (optional) |

---

## âš ï¸ DO NOT Remove (core pipeline)

| Script | Purpose | Critical? |
|--------|---------|-----------|
| `opticonn_hub.py` | Main entry point | ğŸ”´ **YES** |
| `run_pipeline.py` | Single combo/full dataset execution | ğŸ”´ **YES** |
| `cross_validation_bootstrap_optimizer.py` | Sweep orchestration | ğŸ”´ **YES** (if doing sweeps) |
| `extract_connectivity_matrices.py` | Connectivity extraction | ğŸ”´ **YES** |
| `aggregate_network_measures.py` | Network metrics | ğŸ”´ **YES** |
| `qa_cross_validator.py` | QA validation + **Layer 1 & 2 prevention** | ğŸ”´ **YES** |
| `bootstrap_qa_validator.py` | Anomaly detection + **Layer 3 prevention** | ğŸ”´ **YES** |
| `validate_setup.py` | Environment validation | ğŸŸ¡ *Useful* |

---

## ğŸ§ª Demo: Minimal Sweep to Understand Flow

```bash
# Navigate to repo
cd /data/local/software/braingraph-pipeline

# Activate environment
source braingraph_pipeline/bin/activate

# Run minimal sweep (2 parameter combinations, 1 subject)
python opticonn.py sweep \
  -i /path/to/test_data/with_some_fz_files \
  -o demo_results \
  --quick \
  --subjects 1 \
  --no-emoji \
  --verbose

# Monitor output
cd demo_results/sweep-*/optimize/
head -20 bootstrap_qa_wave_1/combo_diagnostics.csv
tail -20 bootstrap_qa_wave_1/combo_diagnostics.csv
```

**What you'll see:**
1. `validate_setup.py` runs first
2. `cross_validation_bootstrap_optimizer.py` launches
3. For each combo: `run_pipeline.py` called
   - DSI Studio extracts connectivity
   - Network metrics computed
   - QA validation runs (Layers 1 & 2)
4. Results written to `combos/sweep_XXXX/`
5. Final summary: `bootstrap_qa_wave_1/combo_diagnostics.csv`
6. Anomaly detection runs (Layer 3)

**You can now understand:**
- Which parameters were tested (sweep grid)
- How many combos ran
- Which QA checks were applied
- What the anomaly detector flagged

---

## ğŸ“ What Each Script Does (50-word summary)

### Core Pipeline
- **`opticonn_hub.py`** â€“ CLI dispatcher; parses args and routes to appropriate workflow (sweep/apply/pipeline)
- **`run_pipeline.py`** â€“ Executes single parameter combo; coordinates extraction, scoring, QA validation
- **`extract_connectivity_matrices.py`** â€“ Calls DSI Studio to build connectivity matrices from DTI data
- **`aggregate_network_measures.py`** â€“ Computes graph properties (efficiency, small-worldness, density) on matrices

### Sweep-Specific
- **`cross_validation_bootstrap_optimizer.py`** â€“ Sweep orchestrator; generates param combos, creates bootstrap waves, runs each combo
- **`sweep_utils.py`** â€“ Grid building utilities (Cartesian product, random/LHS sampling, MATLAB range parsing)
- **`run_parameter_sweep.py`** â€“ Legacy parameter grid generator (can remove if not needed)

### Validation & Prevention
- **`qa_cross_validator.py`** â€“ QA checks and prevention layers 1 & 2 (normalization bounds, success detection)
- **`bootstrap_qa_validator.py`** â€“ Anomaly detection and prevention layer 3 (flags suspicious patterns)
- **`validate_setup.py`** â€“ Pre-flight checks (deps, DSI Studio, config validity)

### Analysis (Optional)
- **`pareto_view.py`** â€“ Post-sweep: analyzes multi-objective trade-offs (cost vs. quality vs. density)
- **`sensitivity_analyzer.py`** â€“ Parameter sensitivity analysis (optional research tool)
- **`statistical_analysis.py`** â€“ Statistical comparisons (optional research tool)

