# Quick Reference: Faulty Optimization Prevention

**TL;DR**: The system now automatically detects and prevents faulty optimization results.

## What Happens Automatically

âœ… Every Bayesian optimization iteration is validated
âœ… Faulty results are automatically marked and excluded
âœ… Best score is never updated from faulty iterations
âœ… Results clearly show which iterations are faulty

## Nothing to Configure

Just run optimization normally:
```bash
python scripts/bayesian_optimizer.py --data-dir ... --output ...
```

Validation runs **automatically**.

## Check Results

**Console Output** (Automatic):
```
Iter |  QA Score |   Status    |      Best Atlas       | Atlas QA
  15 |    0.0000 | âŒ FAULTY   | Extraction failure    |   N/A
  14 |    0.6234 | âœ“ Valid     | FreeSurferDKT_Cortical| 0.6234

âš ï¸  FAULTY ITERATIONS DETECTED AND FLAGGED: 1/25
```

**Progress File**:
```bash
jq '.all_iterations[] | select(.faulty == true)' results/bayesian_optimization_progress.json
```

## What Gets Checked

| Check | Catches |
|-------|---------|
| Connectivity files | Partial extraction failures (count=OK, FA=FAIL) |
| Score normalization | Artificial 1.0 scores from single subjects |
| Output files | Missing or inaccessible result files |
| Metric validity | Out-of-range or NaN values |

## Faulty Iteration Examples

**"Connectivity matrix extraction failure"**
- Only some metrics generated (e.g., count succeeded but FA failed)
- Not all .connectivity.mat files present

**"Artificial quality score (single subject)"**
- All quality scores identical
- Normalized to 1.0 despite no variation

**"Missing connectivity matrices"**
- Results directory doesn't have expected structure
- No .connectivity.mat files found

**"Invalid network metrics"**
- Metrics outside valid ranges (e.g., density > 1.0)
- NaN or infinite values in results

## Debug a Faulty Iteration

```bash
# Check extraction summary
cat results/iterations/iteration_0015/01_extraction/logs/extraction_summary.json

# View all results
cat results/iterations/iteration_0015/01_extraction/logs/processing_results.csv

# Check optimization output
cat results/iterations/iteration_0015/02_optimization/optimized_metrics.csv
```

## How the System Works

```
Iteration runs
    â†“
Validation: Check 4 criteria
    â†“
If FAULTY:           If VALID:
  Mark faulty        Accept score
  QA = 0.0           Update best_score
  Skip best_score    Continue
  â†“                  â†“
(Next iteration) (Next iteration)
```

## Test It

All validation is tested:
```bash
PYTHONPATH=/data/local/software/braingraph-pipeline \
  python scripts/test_integrity_checks.py
```

Expected: **6/6 tests passing** âœ…

## Files That Changed

| File | What Changed |
|------|--------------|
| `extract_connectivity_matrices.py` | Added file verification method |
| `metric_optimizer.py` | Fixed single-subject score normalization |
| `bayesian_optimizer.py` | Added validation before accepting results |

## FAQ

**Q: Do I need to do anything?**  
A: No, it's automatic. Just run optimization normally.

**Q: What if an iteration is marked faulty?**  
A: The system automatically excludes it from best score. No manual action needed.

**Q: Can I override faulty detection?**  
A: No. Faulty means something went wrong. Check the logs instead.

**Q: Will this slow down optimization?**  
A: No, validation adds < 1% overhead.

**Q: What if all iterations are faulty?**  
A: Check your input data or configuration. Something systemic is wrong.

## Key Points

ðŸ›¡ï¸ **Automatic** - No configuration required  
âœ“ **Transparent** - Faulty results clearly marked  
ðŸ”’ **Safe** - Faulty results never affect best score  
ðŸ“Š **Visible** - Status column in results  
âœ… **Tested** - 6/6 test cases passing  

## Everything Works Out of the Box

You don't need to:
- Configure validation
- Set any flags
- Monitor anything manually
- Verify results differently

The system automatically:
- Validates every iteration
- Marks faulty results
- Prevents bad results from corrupting best parameters
- Shows you exactly what happened

**Result**: Never again will suspicious iterations like 1.0000 QA from a single subject corrupt your optimization.

---

**For details**: See FAULTY_OPTIMIZATION_FIX_LOG.md  
**For technical info**: See INTEGRITY_CHECKS.md  
**For user guide**: See PREVENTION_SYSTEM.md
